{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de865903-d5d6-4388-bfc9-08af15b67b51",
   "metadata": {},
   "source": [
    "# Denoising using the Analytical Score Function for the ${\\rm SU}(N)$ Heat Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7355f6-7188-46ad-8d75-571b04985fb9",
   "metadata": {},
   "source": [
    "In this notebook, we will show how knowledge of the analytical score function for the heat kernel can be used to \"undo,\" or *denoise*, a forward diffusion process that takes initial data into corrupted noisy samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ead69-4198-473d-bb1d-411d34765f60",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadcb206-8144-4d5d-a8c1-549ddc6ad60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92b869-d0ac-4102-97e9-cf993e321f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our repo\n",
    "import sys\n",
    "sys.path.insert(0, '..')  # repo source code\n",
    "\n",
    "from src.linalg import trace, adjoint\n",
    "from src.diffusion import VarianceExpandingDiffusion, VarianceExpandingDiffusionSUN\n",
    "from src.sun import (\n",
    "    proj_to_algebra, matrix_exp, matrix_log,\n",
    "    random_sun_element, random_un_haar_element,\n",
    "    group_to_coeffs, coeffs_to_group,\n",
    "    extract_sun_algebra, embed_diag, mat_angle\n",
    ")\n",
    "from src.canon import canonicalize_sun\n",
    "from src.heat import (\n",
    "    eucl_score_hk,\n",
    "    sun_score_hk, sample_sun_hk, sun_hk, _sun_hk_unwrapped\n",
    ")\n",
    "from src.utils import grab, wrap\n",
    "from src.devices import set_device, get_device, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b716eb-71b2-4951-8a25-40e572e633c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_device('cpu')\n",
    "print(summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9120121b-cccd-4683-ab8e-a77fe17a1967",
   "metadata": {},
   "source": [
    "## Euclidean Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc4858-8ed3-4b44-93d4-e304261ce0bf",
   "metadata": {},
   "source": [
    "Variance-expanding diffusion is a stochastic process described by $$dx = g(t) dW$$ that corresponds to the heat equation: $$\\partial_t u(x, t) = \\frac{g(t)^2}{2} \\Delta u(x, t),$$ where $g^2$ is a postive, time-dependent scalar quantity we call the *diffusivity*. The differential operator $\\Delta$ is the Laplace-Beltrami operator on whatever ambient space the samples $x$ occupy. In Euclidean space, $x \\in \\mathbb{R}^n$, $\\Delta$ is just the familiar Laplacian given by $\\Delta := \\sum_{i=1}^n \\partial_i^2$. In particuar, for a single, real-valued degree of freedom (with constant unit diffusivity), the heat equation is $$\\partial_t u = \\partial_x^2 u,$$ and the fundamental solution (Green's function / propagator) for this PDE is called the *Heat Kernel* and is given by $$K(x, t) = \\frac{1}{\\sqrt{2\\pi\\sigma(t)^2}}e^{-\\frac{x^2}{2\\sigma(t)^2}},$$ where $\\sigma(t)$ is the marginal standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7e9a5-d9bf-47f5-8001-171d099c7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_heat_kernel(x, t, width=None):\n",
    "    \"\"\"Computes the Euclidean heat kernel density K(x, t) for `x` at time `t`.\"\"\"\n",
    "    if width is None:\n",
    "        width = t**0.5  # assume unit constant diffusivity\n",
    "    normalization = 1 / (2 * np.pi * width**2)**0.5\n",
    "    weight = torch.exp(-x**2 / (2 * width**2))\n",
    "    return normalization * weight\n",
    "\n",
    "\n",
    "def _visualize_heat_kernel():\n",
    "    xs = torch.linspace(-4, 4, 100)\n",
    "    times = np.linspace(0.05, 1, 20)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    cmap = mpl.colormaps.get_cmap('viridis')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('Heat Kernel Density')\n",
    "    for t in times:\n",
    "        line = ax.plot(xs, euclidean_heat_kernel(xs, t), color=cmap(t))#, label=f'$t = {t}$')\n",
    "    time_colors = mpl.cm.ScalarMappable(mpl.colors.Normalize(times[0], times[-1]))\n",
    "    cbar = fig.colorbar(time_colors, cmap=cmap, ax=ax, label='$t$')\n",
    "    fig.show()\n",
    "\n",
    "_visualize_heat_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f80cc6-c935-4969-b97b-b94ae917be62",
   "metadata": {},
   "source": [
    "One can easily sample from the Euclidean heat kernel at arbitrary time $t$; since $K(x, t)$ is always a normal distribution, you only need to know the marginal standard deviation at $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa630e-2fec-4b5a-a8de-3898ffbd5caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_euclid_hk(batch_size, t, width=None):\n",
    "    \"\"\"Generates `batch_size` samples from the Euclidean\n",
    "    Heat kernel at time `t` with width `width`.\"\"\"\n",
    "    if width is None:\n",
    "        width = t**0.5\n",
    "    x_t = width * torch.randn((batch_size,))\n",
    "    return x_t\n",
    "\n",
    "def _test_sample_hk():\n",
    "    batch_size = 16384\n",
    "    xs = torch.linspace(-4, 4, 100)\n",
    "    times = [0.1, 0.5, 1.0]\n",
    "    \n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('Density')\n",
    "    for t in times:\n",
    "        xt = sample_euclid_hk(batch_size, t)\n",
    "        ax.hist(xt, bins=50, density=True, color=cmap(t), alpha=0.55, label=f'Heat kernel samples at $t = {t}$')\n",
    "        ax.plot(xs, euclidean_heat_kernel(xs, t), ls='--', color=cmap(t), label=f'Analytical HK at $t = {t}$')\n",
    "    fig.legend(loc='right', fontsize='small')\n",
    "    ax.set_title('Heat Kernel Density')\n",
    "    fig.show()\n",
    "\n",
    "_test_sample_hk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c71a57-c51d-4197-855f-4e6278b83a4e",
   "metadata": {},
   "source": [
    "It is also easy to simulate the forward process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c113a76-49d6-4427-9939-00d4f3aca3eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_euclid_fwd():\n",
    "    \"\"\"Simulates forward Euclidean VE diffusion process.\"\"\"\n",
    "    batch_size = 4096\n",
    "    x_0 = torch.zeros((batch_size, 1))\n",
    "    diffuser = VarianceExpandingDiffusion(sigma=1.1)\n",
    "    \n",
    "    xs = torch.linspace(-4, 4, 100)\n",
    "    times = [0.01, 0.1, 0.5, 1.0]\n",
    "    cmap = mpl.colormaps.get_cmap('viridis')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(times), figsize=(4*len(times), 4), sharey=True)\n",
    "    fig.suptitle('Density During Forward Process')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    for t, ax in zip(times, axes):\n",
    "        # Samples stats should match params of analytical HK\n",
    "        x_t = diffuser(x_0, torch.tensor(t).repeat(batch_size))\n",
    "        sigma_t = diffuser.sigma_func(t)\n",
    "        assert torch.allclose(torch.std(x_t), sigma_t, atol=5e-2), \\\n",
    "            f'StDev of samples {torch.std(x_t).item():.4f} does not match marginal HK StDev {sigma_t:.4f}'\n",
    "        \n",
    "        # Visualize forward process over time\n",
    "        ax.set_title(f'$t = {t}$')\n",
    "        ax.set_xlabel('$x$')\n",
    "        ax.hist(x_t, bins=50, density=True, color=cmap(t), alpha=0.55, label=f'Diffused samples at $t = {t}$')\n",
    "        ax.plot(xs, euclidean_heat_kernel(xs, t, width=sigma_t), ls='--', color=cmap(t), label=f'Analytical HK at $t = {t}$')\n",
    "        ax.legend()\n",
    "    fig.show()\n",
    "\n",
    "visualize_euclid_fwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba69a14-4719-4a05-ab07-a24653d9ee27",
   "metadata": {},
   "source": [
    "It is easy to compute the analytical score function for the Euclidean heat kernel:\n",
    "\n",
    "$$s(x, t) = \\partial_x \\log K(x, t) = -\\frac{x}{\\sigma(t)^2}$$\n",
    "\n",
    "which can be used to solve the reverse SDE: $$d\\tilde{x} = -g(t)^2 s(x, t)dt + g(t) dW$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e2b13-26fa-450a-ba4a-1c6f9376536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_backward(x_1, diffuser, num_steps=200, solver_type='ODE'):\n",
    "    dt = 1 / num_steps\n",
    "    t = 1.0\n",
    "    x_t = x_1.clone()\n",
    "\n",
    "    trajectories = []\n",
    "    for step in range(num_steps):\n",
    "        sigma_t = diffuser.sigma_func(t)\n",
    "        g_t = diffuser.noise_coeff(t)\n",
    "        score = eucl_score_hk(x_t, width=sigma_t)\n",
    "        \n",
    "        # Integration step\n",
    "        if solver_type == 'ODE':\n",
    "            x_t = x_t + 0.5 * g_t**2 * score * dt\n",
    "        elif solver_type == 'SDE':\n",
    "            x_t = x_t + 0.5*g_t**2 * score * dt + g_t * torch.rand_like(x_t) * dt**0.5  # TODO: debug\n",
    "        else:\n",
    "            raise NotImplementedError(f'Integration method {solver_type} not supported')\n",
    "        t -= dt\n",
    "        trajectories.append(x_t)\n",
    "    return x_t, trajectories\n",
    "\n",
    "\n",
    "def _test_denoise():\n",
    "    batch_size = 8192\n",
    "    x_1 = sample_euclid_hk(batch_size, t=1.0)\n",
    "    diffuser = VarianceExpandingDiffusion(sigma=1.1)\n",
    "    \n",
    "    num_steps = 200\n",
    "    x_0, trajectories = denoise_backward(x_1, diffuser, num_steps)\n",
    "    \n",
    "    cmap = mpl.colormaps.get_cmap('viridis')\n",
    "    xs = torch.linspace(-4, 4, 100)\n",
    "    steps = [20, 50, 150, 195]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(steps), figsize=(4*len(steps), 4), sharey=True)\n",
    "    fig.suptitle('Density During Reverse Process')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    for ax, step in zip(axes, steps):\n",
    "        # Check that stats of denoised samples match params of analytical HK\n",
    "        t = 1 - step/num_steps\n",
    "        x_t = trajectories[step]\n",
    "        sigma_t = diffuser.sigma_func(t)\n",
    "        #assert torch.allclose(torch.std(x_t), sigma_t, atol=5e-2), \\\n",
    "        #    f'StDev of samples {torch.std(x_t).item():.4f} does not match marginal HK StDev {sigma_t:.4f}'\n",
    "        \n",
    "        # Display reverse process plots\n",
    "        ax.set_title(f'$t = {t:.3f}$')\n",
    "        ax.set_xlabel('$x$')\n",
    "        hk = euclidean_heat_kernel(xs, t)\n",
    "        hk /= hk.sum() * (xs[1] - xs[0])\n",
    "        ax.plot(xs, hk, ls='--', color=cmap(t), label=f'Analytic HK')\n",
    "        ax.hist(x_t, bins=50, color=cmap(t), alpha=0.55, density=True, label=f'Denoised samples')\n",
    "        ax.legend(fontsize=7.5)\n",
    "    fig.show()\n",
    "\n",
    "_test_denoise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4f582-6260-4d13-9afc-ec2438d162c7",
   "metadata": {},
   "source": [
    "## ${\\rm SU}(N)$ Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd86fd3-236e-478c-903c-e86efb4774bd",
   "metadata": {},
   "source": [
    "We can do the same analytical noising-denoising procedure for an SU(2) variable on the group space in exact analogy to the previous results in Euclidean space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f9113-d395-4ee0-8b88-e5efc1ffc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sun_hk():\n",
    "    xs = torch.linspace(-np.pi, np.pi, 100).unsqueeze(-1)\n",
    "    times = torch.linspace(0, 1, 10)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    cmap = mpl.colormaps.get_cmap('viridis')\n",
    "    ax.set_xlabel(r'$\\theta$')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('SU(2) Spetral Heat Kernel')\n",
    "    for t in times:\n",
    "        ax.plot(xs, sun_hk(xs, width=t**0.5, n_max=1), color=cmap(t))\n",
    "    time_colors = mpl.cm.ScalarMappable(mpl.colors.Normalize(times[0], times[-1]))\n",
    "    cbar = fig.colorbar(time_colors, cmap=cmap, ax=ax, label='$t$')\n",
    "    fig.show()\n",
    "\n",
    "visualize_sun_hk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f130bb2-1363-4fb1-8aef-60599021a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sample_sun_hk():\n",
    "    batch_size = 2048\n",
    "    Nc = 2\n",
    "    _U_0_re = torch.eye(Nc).repeat(batch_size, 1, 1)\n",
    "    _U_0_im = torch.zeros((batch_size, Nc, Nc))\n",
    "    U_0 = torch.complex(_U_0_re, _U_0_im)\n",
    "\n",
    "    # Diffusion process\n",
    "    sigma = 1.1\n",
    "    diffuser = VarianceExpandingDiffusionSUN(sigma)\n",
    "\n",
    "    times = [0.1, 0.5, 0.9, 1.0]\n",
    "    #xs = torch.linspace(-np.pi, np.pi, 100).unsqueeze(-1)  \n",
    "    xs = torch.linspace(0, np.pi, 100).unsqueeze(-1) # `sample_sun_hk` canonicalizes angles, so better to look at [0, pi]\n",
    "    cmap = mpl.colormaps.get_cmap('viridis')\n",
    "\n",
    "    # Compare samples from the heat kernel to the analytical heat kernel at each time\n",
    "    fig, axes = plt.subplots(1, len(times), figsize=(4*len(times), 4), sharey=True)\n",
    "    fig.suptitle('Samples from the SU(2) Heat Kernel over Time')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    for t, ax in zip(times, axes):\n",
    "        sigma_t = diffuser.sigma_func(t)\n",
    "        x_t = sample_sun_hk(batch_size, Nc=2, width=sigma_t.repeat(batch_size), n_iter=25)  # more IS iters for better sample quality at small t\n",
    "        hk = sun_hk(xs, width=sigma_t, n_max=3, eig_meas=True)\n",
    "        hk /= hk.sum() * (xs[1] - xs[0])\n",
    "        ax.hist(x_t[:, 0], bins=50, density=True, color=cmap(t), alpha=0.55, label='HK samples')\n",
    "        ax.plot(xs, hk, color=cmap(t), ls='--', label='Analytic SU(2) HK')\n",
    "        ax.set_xlabel(r'$\\theta$')\n",
    "        ax.set_title(f'$t = {t}$')\n",
    "        ax.legend()\n",
    "    fig.show()\n",
    "\n",
    "test_sample_sun_hk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096131ba-d24d-49f3-8ec9-677fa4559dff",
   "metadata": {},
   "source": [
    "Simulate the forward diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbe507-d0a0-432c-af55-ec05ac1313dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sun_fwd_diffusion():\n",
    "    # Create initial data (2x2 identity matrices)\n",
    "    batch_size = 4096\n",
    "    Nc = 2\n",
    "    _U_0_re = torch.eye(Nc).repeat(batch_size, 1, 1)\n",
    "    _U_0_im = torch.zeros((batch_size, Nc, Nc))\n",
    "    U_0 = torch.complex(_U_0_re, _U_0_im)\n",
    "\n",
    "    # Diffusion process\n",
    "    sigma = 1.1\n",
    "    diffuser = VarianceExpandingDiffusionSUN(sigma)\n",
    "\n",
    "    times = [0.1, 0.5, 0.75, 0.99]\n",
    "    xs = torch.linspace(-np.pi, np.pi, 100).unsqueeze(-1)\n",
    "    cmap = mpl.colormaps.get_cmap('viridis')\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(times), figsize=(4*len(times), 4), sharey=True)\n",
    "    fig.suptitle('SU(2) Angular Spectral Density over Forward Process')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    for t, ax in zip (times, axes):\n",
    "        # Forward diffusion\n",
    "        U_t, X_t, V = diffuser.diffuse(U_0, t=t*torch.ones((batch_size,)), n_iter=25)  # diffuse from t=0 -> t=T\n",
    "        thetas, _, _ = mat_angle(U_t)\n",
    "        sigma_t = diffuser.sigma_func(t)\n",
    "\n",
    "        # Analytical HK\n",
    "        hk = sun_hk(xs, width=diffuser.sigma_func(t), n_max=5, eig_meas=True)\n",
    "        hk /= hk.sum() * (xs[1] - xs[0])\n",
    "        print(f'sigma({t}):', sigma_t.item())\n",
    "        \n",
    "        # Plot snapshots\n",
    "        ax.set_title(f'$t = {t}$')\n",
    "        ax.set_xlabel(r'$\\theta$')\n",
    "        ax.hist(thetas[:, 0], bins=50, density=True, color=cmap(t), alpha=0.65, label='Diffused Samples')\n",
    "        ax.plot(xs, hk, color=cmap(t), ls='--', label='Analytical HK')\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "visualize_sun_fwd_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ef4d92-ad40-4e58-8544-4bc23d3ca12b",
   "metadata": {},
   "source": [
    "Simulate the reverse (denoising) process using the analytically known score for the SU(N) heat kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494615d-e305-4127-8ac0-102dba228426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sun_gaussian(shape):\n",
    "    Nc, Nc_ = shape[-2:]\n",
    "    assert Nc == Nc_\n",
    "    return proj_to_algebra(torch.randn(shape) + 1j*torch.randn(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32057f-e729-49a7-869d-075eb0b26489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_backwards(U_1, diffuser, num_steps=200, verbose=False, solve_type='SDE'):\n",
    "    trajectories = []\n",
    "    dt = 1 / num_steps\n",
    "    t = 1.0\n",
    "    U_t = U_1.clone()\n",
    "    for step in tqdm.tqdm(range(num_steps)):\n",
    "        # Eigendecompose\n",
    "        x_t, V, V_inv = mat_angle(U_t)\n",
    "\n",
    "        # Get SDE params\n",
    "        sigma_t = diffuser.sigma_func(t)\n",
    "        g_t = diffuser.noise_coeff(t)\n",
    "        score = sun_score_hk(x_t[..., :-1], width=sigma_t)\n",
    "\n",
    "        # Integration step in reverse time\n",
    "        if solve_type == 'ODE':\n",
    "            x_t = x_t + 0.5 * g_t**2 * score * dt  # ODE Euler step on spectra\n",
    "            D = embed_diag(torch.exp(1j * x_t)).to(V)\n",
    "            U_t = V @ D @ V_inv\n",
    "        elif solve_type == 'SDE':\n",
    "            x_t = x_t + g_t**2 * score * dt  # SDE Euler-Maruyama drift step on spectra\n",
    "            D = embed_diag(torch.exp(1j * x_t)).to(V)\n",
    "            U_t = V @ D @ V_inv\n",
    "            U_t = matrix_exp(g_t * dt**0.5 * sample_sun_gaussian(U_t.shape)) @ U_t  # SDE noise step    \n",
    "        else:\n",
    "            raise NotImplementedError(f'Integration method {solve_type} not implemented')\n",
    "        t -= dt\n",
    "\n",
    "        # Collect and print metrics\n",
    "        trajectories.append(U_t)\n",
    "        if verbose:\n",
    "            print(f'Step {step}/{num_steps} | trace(U) = {trace(U_t/Nc).mean().item():.6f}')\n",
    "            print()\n",
    "\n",
    "    return U_t, trajectories\n",
    "\n",
    "\n",
    "def _test_denoise_sun():\n",
    "    # Initial data: 2x2 identity matrices\n",
    "    batch_size = 1024\n",
    "    Nc = 2\n",
    "    _U_0_re = torch.eye(Nc).repeat(batch_size, 1, 1)\n",
    "    _U_0_im = torch.zeros((batch_size, Nc, Nc))\n",
    "    U_0 = torch.complex(_U_0_re, _U_0_im)\n",
    "\n",
    "    # Diffuse: U_0 -> U_1\n",
    "    sigma = 1.1\n",
    "    diffuser = VarianceExpandingDiffusionSUN(sigma)\n",
    "    U_1, _, _ = diffuser.diffuse(U_0, torch.ones(batch_size), n_iter=25)\n",
    "    \n",
    "    # Denoise: U_1 -> U_0'\n",
    "    U_0, trajectories = denoise_backwards(U_1, diffuser, num_steps=200, solve_type='ODE')\n",
    "    print(\"Re[U_0'] =\\n\", grab(U_0.mean(0)).real)\n",
    "    print(\"Im[U_0'] =\\n\", grab(U_0.mean(0)).imag)\n",
    "\n",
    "    # Plot reverse trajectories\n",
    "    times = [1.0, 0.75, 0.25, 0.05]\n",
    "    cmap = mpl.colormaps.get_cmap('viridis')\n",
    "    fig, axes = plt.subplots(1, len(times), figsize=(4*len(times), 4), sharey=True)\n",
    "    fig.suptitle('SU(2) Angular Spectral Density During Reverse Process')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    xs = torch.linspace(-np.pi, np.pi, 100).unsqueeze(-1)\n",
    "    for t, ax in zip(times, axes):\n",
    "        # Histogram denoised samples\n",
    "        step = int((1 - t) * len(trajectories))\n",
    "        U_t = trajectories[step]\n",
    "        x_t, _, _ = mat_angle(U_t)\n",
    "        ax.hist(x_t[:, 0], bins=50, density=True, color=cmap(t), alpha=0.65, label='Denoised samples')\n",
    "        \n",
    "        # Analytical HK spectral density\n",
    "        hk = sun_hk(xs, width=diffuser.sigma_func(t), n_max=3)\n",
    "        hk /= hk.sum() * (xs[1] - xs[0])\n",
    "        \n",
    "        # Plot\n",
    "        ax.plot(xs, hk, color=cmap(t), ls='--', label='Analytical HK')\n",
    "        ax.set_title(f'$t = {t}$')\n",
    "        ax.set_xlabel(r'$\\theta$')\n",
    "        ax.legend()\n",
    "    fig.show()\n",
    "\n",
    "_test_denoise_sun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a2291-2f2a-4d8c-af29-0af224029948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
