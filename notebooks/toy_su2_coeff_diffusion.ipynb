{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82603ad-9544-4dc2-998b-006774f5ea67",
   "metadata": {},
   "source": [
    "# Diffusion for a Toy SU(2) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f287b9-ab2c-481d-ad19-7750a4c4fde6",
   "metadata": {},
   "source": [
    "In this notebook, we look at a toy matrix model defined in terms of a single ${\\rm SU}(2)$ degree of freedom occupying a single site on a zero dimensional lattice. The toy action we work with is given by $$S[U] = -\\frac{\\beta}{2} {\\rm Re}{\\rm Tr}(U),$$ where $\\beta$ is a coupling strength.\n",
    "\n",
    "The diffusion model setup will be entirely Euclidean in the variance-expanding picture. Our approach will be to take pre-generated configurations $U$, project them into the Lie Algebra, and extract the 3 coefficients on the group generators to use as diffusion data.\n",
    "\n",
    "$$U \\xrightarrow{\\log} A = \\sum_j c_j \\sigma_j \\xrightarrow{\\langle \\sigma_j, \\cdot\\rangle} \\left\\{c_j\\right\\}_{j=1, 2, 3}$$\n",
    "Then we \"do\" the diffusion (training and sampling in the usual way) to obtain new generator coefficients, then recompose these coefficients into new ${\\rm SU}(2)$ matrices:\n",
    "\n",
    "$$ \\left\\{c_j'\\right\\}_{j=1, 2, 3} \\xrightarrow{\\text{recombine}} \\sum_j c_j' \\sigma_j = A' \\xrightarrow{\\text{exponentiate}} \\exp(iA') = U'$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f44044-903a-4dcc-9216-c0763653524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275077db-b077-4f51-97c5-f35fae7309eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our repo\n",
    "import sys\n",
    "sys.path.insert(0, '..')  # repo source code\n",
    "\n",
    "from src.linalg import trace, adjoint\n",
    "from src.action import SUNToyAction\n",
    "from src.diffusion import VarianceExpandingDiffusion\n",
    "from src.sun import (\n",
    "    proj_to_algebra, \n",
    "    random_sun_element,\n",
    "    group_to_coeffs, coeffs_to_group\n",
    ")\n",
    "\n",
    "from src.utils import grab\n",
    "from src.devices import set_device, get_device, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743be0c-2eeb-4804-aa04-819a6f8ca70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a device\n",
    "import src.devices as devices  # from our src code\n",
    "\n",
    "devices.set_device('cpu')\n",
    "print(devices.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3c9e4-3b00-4b0e-afcb-f7b9f1262c64",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "\n",
    "For this example, we will try to learn a target density defined by our simple toy action. To learn this density through a diffusion model, we require training data. We will generate training configs by the Metropolis algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d22130-ec6d-41ee-b989-d9cb283b4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and test a toy SU(2) matrix action\n",
    "def _test_action():\n",
    "    batch_size = 3\n",
    "    Nc = 2\n",
    "    U = random_sun_element(batch_size, Nc=2)\n",
    "\n",
    "    action = SUNToyAction(beta=1.0)\n",
    "    print('Action evaluated on configs:', grab(action(U)))\n",
    "\n",
    "_test_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39890fb-5c2c-4229-af69-39267c3baf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_metropolis(batch_size, Nc, action, num_steps, step_size):\n",
    "    \"\"\"Batched Metropolis sampler.\"\"\"\n",
    "    action_vals = []\n",
    "    accept_rates = []\n",
    "    \n",
    "    U = random_sun_element(batch_size, Nc=Nc)\n",
    "    for _ in range(num_steps):\n",
    "        # Proposal\n",
    "        V_re = torch.eye(Nc).repeat(batch_size, 1, 1) \n",
    "        V_im = step_size * torch.randn((batch_size, Nc, Nc))\n",
    "        V = V_re + 1j*V_im\n",
    "        V = torch.matrix_exp(1j*proj_to_algebra(V))  # random group noise\n",
    "        Up = V @ U\n",
    "        dS = action(Up) - action(U)\n",
    "\n",
    "        # Accept / Reject\n",
    "        r = torch.rand((batch_size,))  # accept w/ prob = exp(-dS)\n",
    "        accept_mask = (r < torch.exp(-dS))[:, None, None]\n",
    "        U = torch.where(accept_mask, Up, U)\n",
    "\n",
    "        action_vals.append(grab(action(U).mean()))\n",
    "        accept_rates.append(grab(torch.sum(accept_mask) / batch_size))\n",
    "\n",
    "    return U, action_vals, accept_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c3b73-ee5c-455e-8e21-15678780aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define physical theory\n",
    "beta = 3.5\n",
    "action = SUNToyAction(beta)\n",
    "\n",
    "\n",
    "# Generate samples\n",
    "num_train = 2 ** 10\n",
    "num_therm = 500\n",
    "num_iters = 1_000\n",
    "step_size = 0.9\n",
    "\n",
    "U_train, action_vals, accept_rates = apply_metropolis(\n",
    "    batch_size = num_train,\n",
    "    Nc = 2,\n",
    "    action = action,\n",
    "    num_steps = num_therm + num_iters,\n",
    "    step_size = step_size\n",
    ")\n",
    "\n",
    "\n",
    "# Visualize Metropolis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Metropolis Steps')\n",
    "\n",
    "axes[0].plot(action_vals)\n",
    "axes[0].set_ylabel('Average Action')\n",
    "\n",
    "axes[1].plot(accept_rates)\n",
    "axes[1].set_ylabel('Acceptance Rate')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e1a04-6fb6-457a-a91f-64aba40fd8be",
   "metadata": {},
   "source": [
    "## Build a score network\n",
    "\n",
    "First we will build a simple score network that acts on the generator coefficients.\n",
    "\n",
    "*Note:* There are two score network implementations worth testing: one with and one without time-dependence (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4239b7-3dc9-4ee2-a1d9-839fed947726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: NO time dependence\n",
    "class SimpleScoreNetSU2(torch.nn.Module):\n",
    "    \"\"\"Time-independent MLP score network for SU(2) generator coefficients.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, 8),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(8, 8),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(8, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t=None):\n",
    "        \"\"\"\n",
    "        Forward pass. \n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Coefficients of Lie group generators\n",
    "            t (Tensor, optional): Time step\n",
    "        \"\"\"\n",
    "        del t\n",
    "        return self.net(x)\n",
    "\n",
    "        \n",
    "def _test_su2_score_net():\n",
    "    score_net = SimpleScoreNetSU2()\n",
    "    U = random_sun_element(batch_size=5, Nc=2)\n",
    "    x = group_to_coeffs(U).real\n",
    "    out = score_net(x)\n",
    "    assert x.shape == out.shape, \\\n",
    "        '[FAILED: Network output must have same shape as input]'\n",
    "    print('[PASSED]')\n",
    "\n",
    "\n",
    "_test_su2_score_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de6bb4-4184-42eb-9dbf-dc1fefc9c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With time dependence (no embedding)\n",
    "class TimeDependentScoreNetSU2(torch.nn.Module):\n",
    "    \"\"\"Time-dependent MLP score network for SU(2) generator coefficients.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 8),  # 3 su2 gens + 1 time\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(8, 8),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(8, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Forward pass. \n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Coefficients of Lie group generators\n",
    "            t (Tensor): Time step\n",
    "        \"\"\"\n",
    "        t = t.unsqueeze(-1)\n",
    "        x = torch.cat([x, t], dim=-1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def _test_su2_score_net():\n",
    "    score_net = TimeDependentScoreNetSU2()\n",
    "    U = random_sun_element(batch_size=5, Nc=2)\n",
    "    x = group_to_coeffs(U).real\n",
    "    t = torch.rand((x.shape[0],))\n",
    "    out = score_net(x, t)\n",
    "    assert x.shape == out.shape, \\\n",
    "        '[FAILED: Network output must have same shape as input]'\n",
    "    print('[PASSED]')\n",
    "\n",
    "\n",
    "_test_su2_score_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd9a5d-102c-4310-8ce4-4548ce78a1ec",
   "metadata": {},
   "source": [
    "## Train the diffusion model\n",
    "\n",
    "We will train our score network using the traditional score matching loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac11a23-59cd-408b-b8cf-071f16bc28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_matching_loss(x_0, score_net, diffuser, tol=1e-5):\n",
    "    t = torch.rand((x_0.shape[0],))\n",
    "    t = (1 - tol) * t + tol  # avoid endpoints where score can become unstable\n",
    "    x_t = diffuser(x_0, t)\n",
    "    \n",
    "    sigma_t = diffuser.sigma_func(t)[:, None]\n",
    "    score = score_net(x_t, t) / sigma_t\n",
    "    eps = (x_t - x_0) / sigma_t\n",
    "    loss = torch.sum((score*sigma_t + eps)**2, dim=-1)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fa20e-6a8a-4003-882e-4b0436d07c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make diffuser\n",
    "sigma = 25\n",
    "diffuser = VarianceExpandingDiffusion(sigma)\n",
    "\n",
    "\n",
    "# Make a score net\n",
    "#score_net = SimpleScoreNetSU2()\n",
    "score_net = TimeDependentScoreNetSU2()\n",
    "\n",
    "\n",
    "# Training hyperparams\n",
    "num_epochs = 1_000\n",
    "lr = 1e-2\n",
    "optimizer = torch.optim.Adam(params=score_net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "x_0 = group_to_coeffs(U_train).real\n",
    "\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = score_matching_loss(x_0, score_net, diffuser)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch} / {num_epochs} | Loss = {loss.item():.6f}')\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04936f83-0fca-40cf-b6bd-cb68ec5c7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss over time\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(losses)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Training Loss')\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1afb6d5-93be-4107-9af2-fd395bdf4bce",
   "metadata": {},
   "source": [
    "## Sample new generator coefficients from the trained model\n",
    "\n",
    "Now we will use simple numerical integration to execute the reverse (denoising) process and recover new data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7b2aa-c1ba-4616-9ed9-3d52b2c40eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = 2 ** 10\n",
    "num_steps = 200\n",
    "\n",
    "new_action_vals = []\n",
    "with torch.no_grad():\n",
    "    # Sample noisy prior data\n",
    "    prior_sigma = diffuser.sigma_func(t=1.0)\n",
    "    x_1 = prior_sigma * torch.randn((num_samples, 3))\n",
    "\n",
    "    # Solve the SDE with Euler-Maruyama\n",
    "    dt = 1 / num_steps\n",
    "    times = torch.linspace(1.0, dt, num_steps)\n",
    "    \n",
    "    x_t = x_1.clone()\n",
    "    for i, t in enumerate(times):\n",
    "        t = t.repeat(num_samples,)\n",
    "        noise = torch.randn_like(x_0)\n",
    "        g_t = diffuser.noise_coeff(t)[:, None]\n",
    "        score = score_net(x_t, t) / diffuser.sigma_func(t)[:, None]\n",
    "        \n",
    "        x_t = x_t + g_t**2 * score * dt + g_t * noise * dt**0.5  # Euler-Maruyama\n",
    "        #x_t = x_t + 0.5 * g_t**2 * score * dt  # Euler\n",
    "        \n",
    "        S = action(coeffs_to_group(x_t))\n",
    "        new_action_vals.append(S.mean().item())\n",
    "        if i % 10 == 0:\n",
    "            print(f'Step {i} / {num_steps} | Action = {S.mean().item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adac9f4-8de6-4ed7-878d-ccc641310b21",
   "metadata": {},
   "source": [
    "## Validation and Visualization\n",
    "\n",
    "To compare our samples, we will look at the average value of the action on the different batches of configurations as well as the density of the eigenangle $\\theta$ where $\\lambda = e^{i\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946505c9-7239-47c2-a6c8-37d2f11eee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_prior = coeffs_to_group(x_1)\n",
    "U_new = coeffs_to_group(x_t)\n",
    "\n",
    "S_prior = action(U_prior).mean().item()\n",
    "S_train = action(U_train).mean().item()\n",
    "S_new = action(U_new).mean().item()\n",
    "print('Action on U_prior:', S_prior)\n",
    "print('Action on U_train:', S_train)\n",
    "print('Action on U_new:', S_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c2d35-084a-4c3a-bb86-e4d17499e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.set_xlabel('Reverse Time Steps')\n",
    "ax.set_ylabel('Average Action')\n",
    "ax.plot(new_action_vals, label='Diffusion Samples')\n",
    "ax.hlines(S_train, xmin=0, xmax=num_steps-1, ls='--', color='black', label='Metropolis Samples')\n",
    "ax.legend()\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3f5ed-087c-4a74-a2a8-97820cde73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data (Metropolis)\n",
    "D_train, _ = torch.linalg.eig(U_train)\n",
    "th_train = torch.angle(D_train)\n",
    "\n",
    "# Prior data (Gaussian)\n",
    "D_prior, _ = torch.linalg.eig(U_prior)\n",
    "th_prior = torch.angle(D_prior)\n",
    "\n",
    "# Posterior data (Diffusion)\n",
    "D_new, _ = torch.linalg.eig(U_new)\n",
    "th_new = torch.angle(D_new)\n",
    "\n",
    "# plot angular densities\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "axes[0].set_ylabel('Density')\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.hist(grab(th_train[:, i]), bins=50, density=True, alpha=0.65, label='Training (Metropolis)')\n",
    "    ax.hist(grab(th_prior[:, i]), bins=50, density=True, alpha=0.5, label='Prior (Gaussian)')\n",
    "    ax.hist(grab(th_new[:, i]), bins=50, density=True, alpha=0.5, label='Diffusion Model')\n",
    "    ax.set_xlabel(rf'$\\theta_{i+1}$')\n",
    "axes[-1].legend()\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
