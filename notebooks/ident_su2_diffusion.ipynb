{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae505614-95df-44e8-8ab3-166dc17d94da",
   "metadata": {},
   "source": [
    "# Diffusion on SU(N) from the identity\n",
    "As a sanity check of our score and training, we attempt to learn the analytical score for diffusion starting from the identity configuration (delta distribution) at $t = 0$. We explore several noise schedules, which just modify the time dependence of the learned score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2dd2d-8470-45f3-8aa0-328ba6951ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e52873-f0cc-4955-9104-3833e68307d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our repo\n",
    "import sys\n",
    "sys.path.insert(0, '..')  # repo source code\n",
    "\n",
    "from src.linalg import trace, adjoint\n",
    "from src.action import SUNToyAction\n",
    "from src.diffusion import VarianceExpandingDiffusionSUN\n",
    "from src.sun import (\n",
    "    proj_to_algebra, matrix_log,\n",
    "    random_sun_element, random_un_haar_element,\n",
    "    group_to_coeffs, coeffs_to_group,\n",
    "    extract_sun_algebra, embed_diag, mat_angle,\n",
    ")\n",
    "from src.heat import sun_score_hk, sample_sun_hk, sun_hk\n",
    "\n",
    "from src.utils import grab, wrap\n",
    "from src.devices import set_device, get_device, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcac280-f108-4876-984d-b8ba88b67ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src\n",
    "importlib.reload(src)\n",
    "importlib.reload(src.diffusion)\n",
    "importlib.reload(src.heat)\n",
    "importlib.reload(src.canon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6829ec1-39e8-45d7-91fe-7d5b5ebfbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a device\n",
    "import src.devices as devices  # from our src code\n",
    "\n",
    "devices.set_device('cpu')\n",
    "print(devices.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c54bc8-9580-4d10-9902-50099b7e7676",
   "metadata": {},
   "source": [
    "# Score network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10aad1a-51ed-4385-885f-3c6d09ac02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDependentScoreNetSUN(torch.nn.Module):\n",
    "    def __init__(self, Nc, n_hidden=8):\n",
    "        super().__init__()\n",
    "        n_in = 2*Nc*Nc + 1 # NxN complex elts + 1 time\n",
    "        n_out = Nc**2 - 1 # number of generators\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_in, n_hidden),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(n_hidden, n_hidden),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(n_hidden, n_hidden),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(n_hidden, n_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = torch.view_as_real(x).flatten(-3)\n",
    "        t = t.unsqueeze(-1)\n",
    "        x = torch.cat([x, t], dim=-1)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364603d8-2ca0-4d53-92d0-209c138b3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_score_net():\n",
    "    # regression to eigenangles\n",
    "    # def loss(xs, score_net):\n",
    "    #     batch_size, Nc = xs.shape\n",
    "    #     V = random_sun_haar_element(batch_size, Nc=Nc)\n",
    "    #     U = V @ embed_diag(torch.exp(1j*xs)).to(V) @ adjoint(V)\n",
    "    #     return ((score_net(U, torch.ones(batch_size))[:,:Nc] - xs)**2).mean()\n",
    "    torch.manual_seed(1235)\n",
    "    batch_size = 16\n",
    "    Nc = 2\n",
    "    # regression to true score\n",
    "    def loss(xs, score_net):\n",
    "        batch_size, Nc = xs.shape\n",
    "        V = random_un_haar_element(batch_size, Nc=Nc)\n",
    "        U = V @ embed_diag(torch.exp(1j*xs)).to(V) @ adjoint(V)\n",
    "        width = 0.1*torch.ones(xs.shape[0])\n",
    "        true_score = sun_score_hk(xs[...,:-1], width=width)\n",
    "        true_score = V @ embed_diag(true_score).to(V) @ adjoint(V)\n",
    "        true_score = extract_sun_algebra(true_score).real\n",
    "        assert torch.all(torch.isfinite(true_score)), f'{true_score=}'\n",
    "        score = score_net(U, torch.ones(batch_size))\n",
    "        assert true_score.shape == score.shape\n",
    "        return ((score - true_score)**2).mean()\n",
    "    # train\n",
    "    score_net = TimeDependentScoreNetSUN(Nc=Nc, n_hidden=64)\n",
    "    optimizer = torch.optim.Adam(score_net.parameters(), lr=3e-4)\n",
    "    hist_loss = []\n",
    "    for _ in tqdm.tqdm(range(5000)):\n",
    "        optimizer.zero_grad()\n",
    "        width = 0.1*torch.ones(batch_size)\n",
    "        # NOTE: important to avoid near-zeros of heat kernel, so sampling should be high quality\n",
    "        xs = torch.tensor(sample_sun_hk(batch_size, Nc, width=width, n_iter=25))\n",
    "        l = loss(xs, score_net)\n",
    "        hist_loss.append(grab(l))\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(hist_loss)\n",
    "    ax.set_yscale('log')\n",
    "    plt.show()\n",
    "_test_score_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e828a-ed24-45ed-844a-45a5d79dbdfb",
   "metadata": {},
   "source": [
    "# Train diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd262ad-f970-4de1-87c3-14a14073dad2",
   "metadata": {},
   "source": [
    "**GK:** This is only partially complete, need to explore further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a5f0a-852f-4a1b-b074-b822ce19bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_matching_loss(x_0, score_net, diffuser, tol=1e-5):\n",
    "    # TODO(gkanwar): Go to back to random selection of t\n",
    "    # t = torch.rand((x_0.shape[0],))\n",
    "    # t = (1 - tol) * t + tol  # avoid endpoints where score can become unstable\n",
    "    t = 0.5*torch.ones((x_0.shape[0],))\n",
    "    x_t, ths, V = diffuser(x_0, t)\n",
    "    \n",
    "    sigma_t = diffuser.sigma_func(t)\n",
    "    score = score_net(x_t, t)\n",
    "    true_score = sun_score_hk(torch.tensor(ths)[...,:-1], width=sigma_t)\n",
    "    true_score = V @ embed_diag(true_score).to(V) @ adjoint(V)\n",
    "    true_score = extract_sun_algebra(true_score).real\n",
    "    assert true_score.shape == score.shape\n",
    "    loss = torch.sum((score - true_score)**2, dim=-1)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2974a67-a22d-4282-811f-b74b6c155026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# physics\n",
    "Nc = 2\n",
    "\n",
    "# diffusion\n",
    "sigma = 1.1 # TODO(gkanwar): update to larger sigma\n",
    "diffuser = VarianceExpandingDiffusionSUN(sigma)\n",
    "\n",
    "# machine learning\n",
    "score_net = TimeDependentScoreNetSUN(Nc=Nc)\n",
    "num_epochs = 1_000\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(params=score_net.parameters(), lr=lr)\n",
    "\n",
    "# training data\n",
    "batch_size = 32\n",
    "x_0 = torch.stack([torch.eye(Nc).cdouble()]*batch_size)\n",
    "\n",
    "# training\n",
    "losses = []\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = score_matching_loss(x_0, score_net, diffuser)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch} / {num_epochs} | Loss = {loss.item():.6f}')\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469444c1-4589-4bc0-89e2-f65c42ea60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(losses)\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c1bb1-fe2d-4629-9dc6-671b92f22351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
